{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pranesh1306/Pranesh1306/blob/main/UNET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dxg6oVWlveUl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3_Lqps1vgEu"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(image_path, target_size):\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.resize(image, target_size, interpolation=cv2.INTER_NEAREST)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert image to RGB\n",
        "    image = image / 255.0  # Normalize by dividing by 255\n",
        "    return image\n",
        "\n",
        "def preprocess_label(label_path, target_size):\n",
        "    label = cv2.imread(label_path)\n",
        "    label = cv2.resize(label, target_size, interpolation=cv2.INTER_NEAREST)\n",
        "    label = cv2.cvtColor(label, cv2.COLOR_BGR2RGB)  # Convert image to RGB\n",
        "    label = label / 255.0  # Normalize by dividing by 255\n",
        "    return label\n",
        "\n",
        "def preprocess_data(image_folder, label_folder, target_size):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    image_files = os.listdir(image_folder)\n",
        "    for image_file in image_files:\n",
        "        image_path = os.path.join(image_folder, image_file)\n",
        "        label_path = os.path.join(label_folder, image_file)\n",
        "\n",
        "        image = preprocess_image(image_path, target_size)\n",
        "        label = preprocess_image(label_path, target_size)\n",
        "\n",
        "        images.append(image)\n",
        "        labels.append(label)\n",
        "\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8M-16uaKvocV"
      },
      "outputs": [],
      "source": [
        "# Paths to the image and label folders\n",
        "import zipfile\n",
        "zip_file_path_1 = \"images.zip\"\n",
        "zip_file_path_2 = \"labels.zip\"\n",
        "\n",
        "# Extract the contents of the zip file\n",
        "with zipfile.ZipFile(zip_file_path_1, 'r') as zip_ref:\n",
        "    zip_ref.extractall('images')  # Extract to the 'images' directory\n",
        "# Extract the contents of the zip file\n",
        "with zipfile.ZipFile(zip_file_path_2, 'r') as zip_ref:\n",
        "    zip_ref.extractall('labels')  # Extract to the 'images' directory    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BGEyhLHz7yT"
      },
      "outputs": [],
      "source": [
        "image_folder = \"/content/images\"\n",
        "label_folder = \"/content/labels\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abrPDYAAvrq4"
      },
      "outputs": [],
      "source": [
        "# Preprocess the data\n",
        "target_size = (256, 256)\n",
        "images, labels = preprocess_data(image_folder,label_folder, target_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJweRUrh0Pkh",
        "outputId": "a21b10fa-2c59-4d8c-cdfa-2a94c856378c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(220, 256, 256, 3)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.shape(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQsxm5TE0UIW"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Create an instance of the ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=90,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3\n",
        ")\n",
        "# Convert the tuples to NumPy arrays\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Reshape the images and labels to match the expected input shape\n",
        "reshaped_images = images.reshape(-1, target_size[0], target_size[1], 3)\n",
        "reshaped_labels = labels.reshape(-1, target_size[0], target_size[1], 3)\n",
        "\n",
        "# Generate augmented images\n",
        "augmented_images = []\n",
        "augmented_labels = []\n",
        "for image in reshaped_images:\n",
        "    augmented_images.extend(datagen.flow(np.expand_dims(image, axis=0), batch_size=1)[0])\n",
        "for label in reshaped_labels:\n",
        "    augmented_labels.extend(datagen.flow(np.expand_dims(label, axis=0), batch_size=1)[0])\n",
        "\n",
        "# Convert the augmented images back to numpy array format\n",
        "augmented_images = np.array(augmented_images)\n",
        "augmented_labels = np.array(augmented_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_53y_Ge0ZeZ"
      },
      "outputs": [],
      "source": [
        "# Combine original and augmented images for training\n",
        "combined_images = np.concatenate((images, augmented_images), axis=0)\n",
        "combined_labels = np.concatenate((labels, augmented_labels), axis=0)\n",
        "\n",
        "# Convert the combined dataset back to separate arrays\n",
        "combined_images = np.array(list(combined_images))\n",
        "combined_labels = np.array(list(combined_labels))\n",
        "\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(combined_images,combined_labels, test_size=0.2, random_state=42)\n",
        "train_images = np.array(train_images)\n",
        "test_images = np.array(test_images)\n",
        "train_labels = np.array(train_labels)\n",
        "test_labels = np.array(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUHxgZuQGbCm",
        "outputId": "774d26dd-07aa-4d4a-fc94-949b9a4b8e4d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(352, 256, 256, 3)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.shape(train_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEg9FZlaCka7",
        "outputId": "980d8437-49e5-4763-dcce-5450bfd7145e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: efficientnet in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from efficientnet) (1.0.8)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from efficientnet) (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.22.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.8.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (3.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (8.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (23.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install efficientnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvaCelrTMp77",
        "outputId": "13cffaa5-36b7-4f26-f9a2-40d18a1e4db9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "22/22 [==============================] - 910s 41s/step - loss: 0.2651 - accuracy: 0.3690 - val_loss: 0.1497 - val_accuracy: 0.0175\n",
            "Epoch 2/10\n",
            "22/22 [==============================] - 934s 43s/step - loss: 0.1323 - accuracy: 0.2154 - val_loss: 0.1222 - val_accuracy: 0.0621\n",
            "Epoch 3/10\n",
            "22/22 [==============================] - 930s 42s/step - loss: 0.1204 - accuracy: 0.1804 - val_loss: 0.1168 - val_accuracy: 0.0169\n",
            "Epoch 4/10\n",
            "22/22 [==============================] - 905s 41s/step - loss: 0.1163 - accuracy: 0.4606 - val_loss: 0.1118 - val_accuracy: 0.4580\n",
            "Epoch 5/10\n",
            "22/22 [==============================] - 915s 42s/step - loss: 0.1196 - accuracy: 0.3439 - val_loss: 0.1130 - val_accuracy: 0.0207\n",
            "Epoch 6/10\n",
            "22/22 [==============================] - 942s 43s/step - loss: 0.1175 - accuracy: 0.3192 - val_loss: 0.1123 - val_accuracy: 0.9285\n",
            "Epoch 7/10\n",
            "22/22 [==============================] - 911s 42s/step - loss: 0.1142 - accuracy: 0.1639 - val_loss: 0.1101 - val_accuracy: 0.3523\n",
            "Epoch 8/10\n",
            "22/22 [==============================] - 934s 43s/step - loss: 0.1125 - accuracy: 0.2881 - val_loss: 0.1124 - val_accuracy: 0.2298\n",
            "Epoch 9/10\n",
            "22/22 [==============================] - 909s 41s/step - loss: 0.1171 - accuracy: 0.4419 - val_loss: 0.1138 - val_accuracy: 0.2373\n",
            "Epoch 10/10\n",
            "22/22 [==============================] - 895s 41s/step - loss: 0.1163 - accuracy: 0.2315 - val_loss: 0.1142 - val_accuracy: 0.0527\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4f2eb58670>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from efficientnet.tfkeras import EfficientNetB0\n",
        "\n",
        "def unet_model(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    # Downsample path\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    # Upsample path\n",
        "    up4 = UpSampling2D(size=(2, 2))(pool2)\n",
        "    up4 = Conv2D(128, 2, activation='relu', padding='same')(up4)\n",
        "    merge4 = concatenate([conv2, up4], axis=3)\n",
        "    conv4 = Conv2D(128, 3, activation='relu', padding='same')(merge4)\n",
        "    conv4 = Conv2D(128, 3, activation='relu', padding='same')(conv4)\n",
        "\n",
        "    up5 = UpSampling2D(size=(2, 2))(conv4)\n",
        "    up5 = Conv2D(64, 2, activation='relu', padding='same')(up5)\n",
        "    merge5 = concatenate([conv1, up5], axis=3)\n",
        "    conv5 = Conv2D(64, 3, activation='relu', padding='same')(merge5)\n",
        "    conv5 = Conv2D(64, 3, activation='relu', padding='same')(conv5)\n",
        "\n",
        "    # Output\n",
        "    outputs = Conv2D(3, 1, activation='sigmoid')(conv5)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Create the U-Net model with EfficientNet backbone\n",
        "input_shape = (256, 256, 3)  # Adjust if necessary\n",
        "model = unet_model(input_shape)\n",
        "\n",
        "# Load pre-trained EfficientNet weights\n",
        "base_model = EfficientNetB0(input_shape=input_shape, include_top=False, weights='imagenet')\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "batch_size = 16  # Adjust if necessary\n",
        "epochs = 10 # Adjust if necessary\n",
        "model.fit(train_images, train_labels, batch_size=batch_size, epochs=epochs, validation_data=(test_images, test_labels))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "# Calculate metrics\n",
        "def calculate_iou(y_true, y_pred):\n",
        "    intersection = np.logical_and(y_true, y_pred)\n",
        "    union = np.logical_or(y_true, y_pred)\n",
        "    iou = np.sum(intersection) / np.sum(union)\n",
        "    return iou\n",
        "\n",
        "def calculate_specificity(y_true, y_pred):\n",
        "    true_negative = np.sum((1 - y_true) * (1 - y_pred))\n",
        "    true_negative_rate = true_negative / np.sum(1 - y_true)\n",
        "    return true_negative_rate\n",
        "\n",
        "def calculate_sensitivity(y_true, y_pred):\n",
        "    true_positive = np.sum(y_true * y_pred)\n",
        "    true_positive_rate = true_positive / np.sum(y_true)\n",
        "    return true_positive_rate\n",
        "\n",
        "accuracy = model.evaluate(test_images, test_labels)[1]\n",
        "iou = calculate_iou(test_labels, predictions)\n",
        "specificity = calculate_specificity(test_labels, predictions)\n",
        "sensitivity = calculate_sensitivity(test_labels, predictions)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"IOU:\", iou)\n",
        "print(\"Specificity:\", specificity)\n",
        "print(\"Sensitivity:\", sensitivity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "s7ywpz4fSNjl",
        "outputId": "60451fe6-d660-4cfc-c853-a14af7c4e096"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2cf2aea5cd71>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Make predictions on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Calculate metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_DkGikT5g9Lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "byX-Bv9FXSib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w7apk_ULRWt3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}