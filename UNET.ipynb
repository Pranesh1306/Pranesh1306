{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pranesh1306/Pranesh1306/blob/main/UNET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Dxg6oVWlveUl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "e3_Lqps1vgEu"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(image_path, target_size):\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.resize(image, target_size, interpolation=cv2.INTER_NEAREST)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert image to RGB\n",
        "    image = image / 255.0  # Normalize by dividing by 255\n",
        "    return image\n",
        "\n",
        "def preprocess_label(label_path, target_size):\n",
        "    label = cv2.imread(label_path)\n",
        "    label = cv2.resize(label, target_size, interpolation=cv2.INTER_NEAREST)\n",
        "    label = cv2.cvtColor(label, cv2.COLOR_BGR2RGB)  # Convert image to RGB\n",
        "    label = label / 255.0  # Normalize by dividing by 255\n",
        "    return label\n",
        "\n",
        "def preprocess_data(image_folder, label_folder, target_size):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    image_files = os.listdir(image_folder)\n",
        "    for image_file in image_files:\n",
        "        image_path = os.path.join(image_folder, image_file)\n",
        "        label_path = os.path.join(label_folder, image_file)\n",
        "\n",
        "        image = preprocess_image(image_path, target_size)\n",
        "        label = preprocess_image(label_path, target_size)\n",
        "\n",
        "        images.append(image)\n",
        "        labels.append(label)\n",
        "\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8M-16uaKvocV"
      },
      "outputs": [],
      "source": [
        "# Paths to the image and label folders\n",
        "import zipfile\n",
        "zip_file_path_1 = \"images.zip\"\n",
        "zip_file_path_2 = \"labels.zip\"\n",
        "\n",
        "# Extract the contents of the zip file\n",
        "with zipfile.ZipFile(zip_file_path_1, 'r') as zip_ref:\n",
        "    zip_ref.extractall('images')  # Extract to the 'images' directory\n",
        "# Extract the contents of the zip file\n",
        "with zipfile.ZipFile(zip_file_path_2, 'r') as zip_ref:\n",
        "    zip_ref.extractall('labels')  # Extract to the 'images' directory    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1BGEyhLHz7yT"
      },
      "outputs": [],
      "source": [
        "image_folder = \"/content/images\"\n",
        "label_folder = \"/content/labels\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "abrPDYAAvrq4"
      },
      "outputs": [],
      "source": [
        "# Preprocess the data\n",
        "target_size = (256, 256)\n",
        "images, labels = preprocess_data(image_folder,label_folder, target_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJweRUrh0Pkh",
        "outputId": "1ed1502b-6974-4512-88f4-796503493307"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(220, 256, 256, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "np.shape(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WQsxm5TE0UIW"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Create an instance of the ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=90,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3\n",
        ")\n",
        "# Convert the tuples to NumPy arrays\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Reshape the images and labels to match the expected input shape\n",
        "reshaped_images = images.reshape(-1, target_size[0], target_size[1], 3)\n",
        "reshaped_labels = labels.reshape(-1, target_size[0], target_size[1], 3)\n",
        "\n",
        "# Generate augmented images\n",
        "augmented_images = []\n",
        "augmented_labels = []\n",
        "for image in reshaped_images:\n",
        "    augmented_images.extend(datagen.flow(np.expand_dims(image, axis=0), batch_size=1)[0])\n",
        "for label in reshaped_labels:\n",
        "    augmented_labels.extend(datagen.flow(np.expand_dims(label, axis=0), batch_size=1)[0])\n",
        "\n",
        "# Convert the augmented images back to numpy array format\n",
        "augmented_images = np.array(augmented_images)\n",
        "augmented_labels = np.array(augmented_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "o_53y_Ge0ZeZ"
      },
      "outputs": [],
      "source": [
        "# Combine original and augmented images for training\n",
        "combined_images = np.concatenate((images, augmented_images), axis=0)\n",
        "combined_labels = np.concatenate((labels, augmented_labels), axis=0)\n",
        "\n",
        "# Convert the combined dataset back to separate arrays\n",
        "combined_images = np.array(list(combined_images))\n",
        "combined_labels = np.array(list(combined_labels))\n",
        "\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(combined_images,combined_labels, test_size=0.2, random_state=42)\n",
        "train_images = np.array(train_images)\n",
        "test_images = np.array(test_images)\n",
        "train_labels = np.array(train_labels)\n",
        "test_labels = np.array(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUHxgZuQGbCm",
        "outputId": "88bb7cf5-45a5-4724-b6ad-8babc8137695"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(352, 256, 256, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "np.shape(train_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEg9FZlaCka7",
        "outputId": "d32d396f-407a-4a04-dd31-35f3c4e3c0c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting efficientnet\n",
            "  Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7 (from efficientnet)\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from efficientnet) (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.22.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.8.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (3.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (8.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (23.1)\n",
            "Installing collected packages: keras-applications, efficientnet\n",
            "Successfully installed efficientnet-1.1.1 keras-applications-1.0.8\n"
          ]
        }
      ],
      "source": [
        "!pip install efficientnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvaCelrTMp77",
        "outputId": "0a5df807-ae43-4325-d4a5-6441d799f0ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b0_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n",
            "16804768/16804768 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "22/22 [==============================] - 1576s 71s/step - loss: 0.2662 - accuracy: 0.4934 - val_loss: 0.1331 - val_accuracy: 0.9845\n",
            "Epoch 2/10\n",
            "22/22 [==============================] - 1556s 71s/step - loss: 0.1273 - accuracy: 0.3841 - val_loss: 0.1124 - val_accuracy: 0.6641\n",
            "Epoch 3/10\n",
            "22/22 [==============================] - 1530s 70s/step - loss: 0.1218 - accuracy: 0.4493 - val_loss: 0.1077 - val_accuracy: 0.0825\n",
            "Epoch 4/10\n",
            "22/22 [==============================] - 1492s 68s/step - loss: 0.1191 - accuracy: 0.3913 - val_loss: 0.1119 - val_accuracy: 0.9471\n",
            "Epoch 5/10\n",
            "22/22 [==============================] - 1494s 68s/step - loss: 0.1173 - accuracy: 0.3816 - val_loss: 0.1043 - val_accuracy: 0.8901\n",
            "Epoch 6/10\n",
            "22/22 [==============================] - 1494s 68s/step - loss: 0.1145 - accuracy: 0.2625 - val_loss: 0.1049 - val_accuracy: 0.5846\n",
            "Epoch 7/10\n",
            "22/22 [==============================] - 1492s 68s/step - loss: 0.1155 - accuracy: 0.4746 - val_loss: 0.1008 - val_accuracy: 0.9225\n",
            "Epoch 8/10\n",
            "22/22 [==============================] - 1495s 68s/step - loss: 0.1145 - accuracy: 0.1567 - val_loss: 0.1068 - val_accuracy: 0.5116\n",
            "Epoch 9/10\n",
            "22/22 [==============================] - 1492s 68s/step - loss: 0.1130 - accuracy: 0.4751 - val_loss: 0.1034 - val_accuracy: 0.8398\n",
            "Epoch 10/10\n",
            "22/22 [==============================] - 1493s 68s/step - loss: 0.1138 - accuracy: 0.3524 - val_loss: 0.1011 - val_accuracy: 0.1762\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f05aa76e7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from efficientnet.tfkeras import EfficientNetB0\n",
        "\n",
        "def unet_model(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    # Downsample path\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    # Upsample path\n",
        "    up4 = UpSampling2D(size=(2, 2))(pool2)\n",
        "    up4 = Conv2D(128, 2, activation='relu', padding='same')(up4)\n",
        "    merge4 = concatenate([conv2, up4], axis=3)\n",
        "    conv4 = Conv2D(128, 3, activation='relu', padding='same')(merge4)\n",
        "    conv4 = Conv2D(128, 3, activation='relu', padding='same')(conv4)\n",
        "\n",
        "    up5 = UpSampling2D(size=(2, 2))(conv4)\n",
        "    up5 = Conv2D(64, 2, activation='relu', padding='same')(up5)\n",
        "    merge5 = concatenate([conv1, up5], axis=3)\n",
        "    conv5 = Conv2D(64, 3, activation='relu', padding='same')(merge5)\n",
        "    conv5 = Conv2D(64, 3, activation='relu', padding='same')(conv5)\n",
        "\n",
        "    # Output\n",
        "    outputs = Conv2D(3, 1, activation='sigmoid')(conv5)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Create the U-Net model with EfficientNet backbone\n",
        "input_shape = (256, 256, 3)  # Adjust if necessary\n",
        "model = unet_model(input_shape)\n",
        "\n",
        "# Load pre-trained EfficientNet weights\n",
        "base_model = EfficientNetB0(input_shape=input_shape, include_top=False, weights='imagenet')\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "batch_size = 16  # Adjust if necessary\n",
        "epochs = 10 # Adjust if necessary\n",
        "model.fit(train_images, train_labels, batch_size=batch_size, epochs=epochs, validation_data=(test_images, test_labels))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "# Calculate metrics\n",
        "def calculate_iou(y_true, y_pred):\n",
        "    intersection = np.logical_and(y_true, y_pred)\n",
        "    union = np.logical_or(y_true, y_pred)\n",
        "    iou = np.sum(intersection) / np.sum(union)\n",
        "    return iou\n",
        "\n",
        "def calculate_specificity(y_true, y_pred):\n",
        "    true_negative = np.sum((1 - y_true) * (1 - y_pred))\n",
        "    true_negative_rate = true_negative / np.sum(1 - y_true)\n",
        "    return true_negative_rate\n",
        "\n",
        "def calculate_sensitivity(y_true, y_pred):\n",
        "    true_positive = np.sum(y_true * y_pred)\n",
        "    true_positive_rate = true_positive / np.sum(y_true)\n",
        "    return true_positive_rate\n",
        "\n",
        "accuracy = model.evaluate(test_images, test_labels)[1]\n",
        "iou = calculate_iou(test_labels, predictions)\n",
        "specificity = calculate_specificity(test_labels, predictions)\n",
        "sensitivity = calculate_sensitivity(test_labels, predictions)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"IOU:\", iou)\n",
        "print(\"Specificity:\", specificity)\n",
        "print(\"Sensitivity:\", sensitivity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7ywpz4fSNjl",
        "outputId": "76c61394-4d2a-488d-c1e5-b5427bc873f1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 100s 30s/step\n",
            "3/3 [==============================] - 93s 29s/step - loss: 0.1011 - accuracy: 0.1762\n",
            "Accuracy: 0.17621733248233795\n",
            "IOU: 0.034485036676580254\n",
            "Specificity: 0.9816249883193205\n",
            "Sensitivity: 0.1515177485692948\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}